from __future__ import annotations

import asyncio
import logging

from dynaconf import Dynaconf
from openai import AsyncOpenAI as OpenAIClient
from openai.types.chat import ChatCompletionMessageParam

from common.conversation import Conversation
from common.message import MESSAGE_ROLE_ASSISTANT, Message

logger = logging.getLogger(__name__)


class OpenAI:
    """OpenAI is a thin wrapper around `openai.AsyncOpenAI` client.
    It stores every message sent by users and generated by the model to DB
    by sending DB events to the event dispatcher
    """

    def __init__(self, base_url: str, api_key: str = "ollama", model: str = "llama3.1"):
        self.model = model
        self.client = OpenAIClient(base_url=base_url, api_key=api_key)

    @classmethod
    def from_dynaconf_settings(cls, settings: Dynaconf) -> OpenAI:
        return OpenAI(
            base_url=settings.llm.openai.base_url,
            api_key=settings.llm.openai.api_key,
            model=settings.llm.openai.model,
        )

    async def generate_response(
        self, prompt: str, converstaion: Conversation
    ) -> Message:
        """generate_response requests the model to generate a response for the given prompt

        Args:
            prompt (str): the user-entered prompted for the model
            converstaion (Conversation): a conversation that provides the message history as a context
        Returns:
            Message: the response generated by the model. Notice that this `Message` object does not have an `id` because it is not stored into DB yet
        """

        # generate message for user's prompt and store in db
        prompt_message = Message(
            conversation_id=converstaion.id, role="user", content=prompt
        )
        messages = self._build_messages(converstaion, prompt_message)
        # TODO: store message in db

        # generate response
        logger.info(f"generating response for prompt: {prompt}")
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
        )
        if not response.choices:
            logger.error(f"no response found, skipping")
        response_message = response.choices[0].message
        logger.info(f"generated resopnse is: {response_message.content}")

        message = Message(
            conversation_id=converstaion.id,
            role=MESSAGE_ROLE_ASSISTANT,
            content=response_message.content,
        )
        # TODO: store message here
        # status should be "draft" because this might not be the final response sent to the dealer
        return message

    def _build_messages(
        conversation: Conversation, message: Message
    ) -> list[ChatCompletionMessageParam]:
        """build a list of OpenAI messages from a `Conversation` and a `Message`

        Args:
            conversation (Conversation): a conversation that contains all the messages in the history
            message (Message): the new prompt entered by user

        Returns:
            list[ChatCompletionMessageParam]: list of messages that can be understood by OpenAI API
        """
