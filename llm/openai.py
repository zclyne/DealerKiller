from __future__ import annotations

import asyncio
import logging

from dynaconf import Dynaconf
from openai import AsyncOpenAI as OpenAIClient
from openai.types.chat import ChatCompletionMessageParam
from prompt import INITIAL_SYSTEM_PROMPT
from sqlalchemy.exc import SQLAlchemyError

import database.database as db
from config import settings
from database.conversation import Conversation
from database.message import (
    MESSAGE_ROLE_ASSISTANT,
    MESSAGE_ROLE_SYSTEM,
    MESSAGE_ROLE_USER,
    Message,
)

logger = logging.getLogger(__name__)


class OpenAI:
    """OpenAI is a thin wrapper around `openai.AsyncOpenAI` client.
    It stores every message sent by users and generated by the model to DB
    by sending DB events to the event dispatcher
    """

    def __init__(self, base_url: str, api_key: str = "ollama", model: str = "llama3.1"):
        self.model = model
        self.client = OpenAIClient(base_url=base_url, api_key=api_key)

    @classmethod
    def from_dynaconf_settings(cls, settings: Dynaconf) -> OpenAI:
        return OpenAI(
            base_url=settings.llm.openai.base_url,
            api_key=settings.llm.openai.api_key,
            model=settings.llm.openai.model,
        )

    async def generate_response(self, prompt: str, conversation: Conversation) -> str:
        """generate_response requests the model to generate a response for the given prompt

        Args:
            prompt (str): the user-entered prompted for the model
            converstaion (Conversation): a conversation that provides the message history as a context
        Returns:
            str: the response generated by the model
        """

        # store prompt in db
        try:
            db.insert_message(MESSAGE_ROLE_USER, prompt, conversation.id)
        except SQLAlchemyError as e:
            logger.error(f"failed to insert message, err={e}")

        # generate response
        messages = self._build_openai_messages(conversation, prompt)

        logger.info(f"generating response for prompt: {prompt}")
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
        )
        if not response.choices:
            logger.error(f"no response found, skipping")
        response_message = response.choices[0].message
        logger.info(f"generated resopnse is: {response_message.content}")

        # store generated response in db
        try:
            db.insert_message(
                MESSAGE_ROLE_ASSISTANT, response_message.content, conversation.id
            )
        except SQLAlchemyError as e:
            logger.error(f"failed to insert message, err={e}")

        # return generated response
        return response_message.content

    def _build_openai_messages(
        conversation: Conversation, prompt: str
    ) -> list[ChatCompletionMessageParam]:
        """build a list of OpenAI messages from a `Conversation` and a `Message`

        Args:
            conversation (Conversation): a conversation that contains all the messages in the history
            prompt (str): the new prompt entered by user

        Returns:
            list[ChatCompletionMessageParam]: list of messages that can be understood by OpenAI API
        """
        # the first message should always be a 'system' message telling the model that it is used to negotiate auto price
        initial_message = Message(
            role=MESSAGE_ROLE_SYSTEM, content=INITIAL_SYSTEM_PROMPT
        )
        prompt_message = Message(role=MESSAGE_ROLE_USER, content=prompt)
        all_messages = [initial_message, *conversation.messages, prompt_message]
        return [_db_message_to_openai_message(m) for m in all_messages]


def _db_message_to_openai_message(message: Message) -> ChatCompletionMessageParam:
    return {"role": message.role, "content": message.content}


_default_openai_client = OpenAI.from_dynaconf_settings(settings)


def openai() -> OpenAI:
    return _default_openai_client
